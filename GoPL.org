# -*- mode:org; -*-

#+title:Go Programming Language
#+subtitle:{{{version}}} {{{date}}}
#+author:LOLH
#+date:2021-10-03 23:03
#+macro:version Version 0.0.8
#+macro:upload-date (eval (current-time-string))
#+bucket:pinecone-forest.com

{{{version}}} {{{date}}}

#+texinfo:@insertcopying


* Preface
:PROPERTIES:
:unnumbered: t
:END:

#+texinfo:@subheading Go's Conception
Go  was conceived  in September  2007 by  Robert Griesemer,  Rob Pike,  and Ken
Thompson, all at Google, and was announced  in November 2009.  The goals of the
language and  its accompanying tools were  to be expressive, efficient  in both
compilation  and  execution,  and  effective in  writing  reliable  and  robust
programs.

#+texinfo:@subheading Similar to but more than C
Go bears  a surface similarity  to C  and, like C,  is a tool  for professional
programmers, achieving maximum effect with minimum  means.  But it is much more
than an updated version of C.  It borrows and adapts good ideas from many other
languages, while avoiding  features that have led to  complexity and unreliable
code.  Its facilities  for concurrency are new and efficient,  and its approach
to data abstraction and object-oriented  programming is unusually flexible.  It
has automatic memory management or garbage collection.

#+texinfo:@subheading Great General-Purpose Programming Language
Go  is  especially  well  suited for  building  infrastructure  like  networked
servers,  and   tools  and  systems  for   programmers,  but  it  is   truly  a
general-purpose  language and  finds use  in  domains as  diverse as  graphics,
mobile  applications,  and  machine  learning.  It  has  become  popular  as  a
replacement for untyped scripting  languages because it balances expressiveness
with safety: Go programs typically run  faster than programs written in dynamic
languages and suffer far fewer crashes due to unexpected type errors.

#+texinfo:@subheading Open-Source Project
Go is an  open-source project, so source code for  its compiler, libraries, and
tools is freely available to anyone.  Contributions to the project come from an
active  worldwide  community.  Go  runs  on  Unix-like systems—Linux,  FreeBSD,
OpenBSD, Mac OS X—and on Plan 9  and Microsoft Windows. Programs written in one
of these environments generally work without modification on the others.

** The Origins of Go
#+texinfo:@heading C-Like Language
Go  is sometimes  described as  a  "C-like language,"  or  as "C  for the  21st
century."

From C, Go inherited its
- expression syntax,
- control-flow statements,
- basic data types,
- call-by-value parameter passing,
- pointers,  and above all,
- C’s emphasis on programs that compile to efficient machine code and cooperate
  naturally with the abstractions of current operating systems.

#+texinfo:@heading Niklaus Wirth
But  there  are other  ancestors  in  Go’s family  tree.  One  major stream  of
influence comes from languages by Niklaus Wirth, beginning with
- Pascal
- Modula-2 inspired the package concept.
- Oberon eliminated the  distinction between module interface  files and module
  implementation files.
- Oberon-2 influenced the syntax for packages, imports, and declarations
- and Object Oberon provided the syntax for method declarations.

#+texinfo:@heading Communicating Sequential Processes (CSP)
Another lineage among  Go’s ancestors, and one that makes  Go distinctive among
recent programming languages, is a  sequence of little-known research languages
developed at Bell Labs, all inspired by the concept of communicating sequential
processes (CSP)  from Tony  Hoare’s seminal  1978 paper  on the  foundations of
concurrency.

In CSP, a  program is a parallel  composition of processes that  have no shared
state; the processes communicate and  synchro- nize using channels. But Hoare’s
CSP  was  a  formal  language   for  describing  the  fundamental  concepts  of
concurrency, not a programming language for writing executable programs.

#+texinfo:@heading Rob Pike Squeak
Rob Pike  and others  began to  experiment with  CSP implementations  as actual
languages. The first was called:
- Squeak
  - ("A language for  communicating with mice"), which provided  a language for
    handling mouse and keyboard events, with statically created channels.
- Newsqueak
  - which offered C-like  statement and expression syntax  and Pascal-like type
    notation.
  - It was a purely functional language with garbage collection, again aimed at
    managing keyboard,  mouse, and  window events.
  - Channels  became first-class  values, dynamically  created and  storable in
    variables.

#+texinfo:@heading Plan 9 and Alef
The Plan  9 operating system carried  these ideas forward in  a language called
Alef.  Alef tried  to make Newsqueak a viable system  programming language, but
its omission of garbage collection made concurrency too painful.

#+texinfo:@heading Miscellaneous Sources
Other constructions  in Go show the  influence of non-ancestral genes  here and
there;
- for example ~iota~ is loosely from =APL=, and
- lexical  scope with  nested functions  is from  =Scheme= (and  most languages
  since).
Here too we find novel mutations.
- Go’s innovative =slices= provide dynamic  arrays with efficient random access
  but  also permit  sophisticated  sharing arrangements  reminiscent of  linked
  lists.
- And the ~defer~ statement is new with Go.

** The Go Project
All programming languages reflect the programming philosophy of their creators,
which  often includes  a significant  component  of reaction  to the  perceived
shortcomings of  earlier languages.   The Go project  was borne  of frustration
with several software  systems at Google that were suffering  from an explosion
of complexity.

#+texinfo:@heading Simplicity
As Rob Pike put it, "complexity  is multiplicative": fixing a problem by making
one part of the system more complex  slowly but surely adds complexity to other
parts.  With constant pressure to  add features and options and configurations,
and to ship code  quickly, it’s easy to neglect simplicity,  even though in the
long run simplicity is the key to good software.

#+texinfo:@subheading Conceptual Integrity vs. Convenience
Simplicity requires more work  at the beginning of a project  to reduce an idea
to  its  essence  and  more  discipline  over the  lifetime  of  a  project  to
distinguish good changes from bad  or pernicious ones.  With sufficient effort,
a good change can be accommodated  without compromising what Fred Brooks called
the  "conceptual integrity"  of  the design  but  a bad  change  cannot, and  a
pernicious change trades simplicity for  its shallow cousin, convenience.  Only
through simplicity of  design can a system remain stable,  secure, and coherent
as it grows.

#+texinfo:@heading What the Go Project Has

The Go project includes
- the language  itself,
- its tools and standard libraries,
and last but not least,
- a cultural agenda of radical simplicity.

As  a recent  high-level language,  Go has  the benefit  of hindsight,  and the
basics are done well: it has
- garbage collection,
- a package system,
- first-class functions,
- lexical  scope,
- a system call interface,  and
- immutable  strings in which text is generally encoded in UTF-8.

#+texinfo:@heading What the Go Project Does Not Have
But  it  has comparatively  few  features  and is  unlikely  to  add more.  For
instance,  it  has
- no implicit  numeric  conversions,
- no constructors  or destructors,
- no operator  overloading,
- no default   parameter  values,
- no inheritance,
- no generics,
- no exceptions,
- no macros,
- no function annotations, and
- no thread-local storage.

The  language is  mature and  stable, and  guarantees backwards  compatibility:
older Go programs can be compiled and  run with newer versions of compilers and
standard libraries.

#+texinfo:@heading Go and its Type System
Go has  enough of a  type system  to avoid most  of the careless  mistakes that
plague programmers in dynamic languages, but  it has a simpler type system than
comparable  typed languages.   This  approach can  sometimes  lead to  isolated
pockets of  "untyped" programming within a  broader framework of types,  and Go
programmers do  not go  to the lengths  that C++ or  Haskell programmers  do to
express  safety properties  as type-based  proofs.   But in  practice Go  gives
programmers  much  of  the  safety  and  run-time  performance  benefits  of  a
relatively strong type system without the burden of a complex one.

#+texinfo:@heading Contemporary System Design
Go encourages an awareness of contemporary computer system design, particularly
the importance  of locality.
- Its *built-in data  types* and most *library data structures*  are crafted to
  work naturally  without explicit initialization or  implicit constructors, so
  relatively few memory allocations and memory writes are hidden in the code.
- Go’s *aggregate  types* (structs  and arrays)  hold their  elements directly,
  requiring less  storage and fewer  allocations and pointer  indirections than
  languages that use indirect fields.
- And since  the modern  computer is  a parallel  machine, Go  has *concurrency
  features* based  on CSP, as  mentioned earlier.  The variable-size  stacks of
  Go’s  lightweight  threads or  goroutines  are  initially small  enough  that
  creating one goroutine is cheap and creating a million is practical.

#+texinfo:@heading Go's Standard Library
Go’s standard library, often described as coming with "batteries included,"
provides clean building blocks and APIs for
- I/O,
- text processing,
- graphics,
- cryptography,
- networking, and
- distributed applications,
- with support for many standard file formats and protocols.

The libraries and tools make extensive use of convention to reduce the need for
configuration  and  explanation,  thus  simplifying program  logic  and  making
diverse Go programs more similar to each other and thus easier to learn.

#+texinfo:@subheading Go Tool
Projects built using  the *go tool* use  only file and identifier  names and an
occasional special comment to determine  all the libraries, executables, tests,
benchmarks,  examples,  platform-specific  variants, and  documentation  for  a
project; the Go source itself contains the build specification.

** Go Sites
- [[https://golang.org][Official Web Site]]
  - [[https://golang.org/doc/][Documentation]]
  - [[https://golang.org/ref/spec][Go Programming Language Specification]]
  - [[https://golang.org/doc/cmd][Go Tool Command Documentation]]
  - [[https://go.dev/learn/][Learning Resources]]

- [[https://pkg.go.dev/std][Go Standard Library]]
  - [[https://cs.opensource.google/go/go][Go Standard Library Source]]

- [[https://blog.golang.org][Go Blog]]
  - best writing on Go

- [[https://play.golang.org][Go Playground]]
  - run Go programs in the browser

- [[https://tour.golang.org][Go Tour]]

- [[https://go.googlesource.com/go][Google Canonical Git Repository]]
  - the Go source files are distributed under the BSD-style license found in
    the =LICENSE= file.

- [[https://github.com/golang/go][Go Source Code Mirror]]

- [[https://golang.org/dl/][Official Binary Distributions]]
  - [[https://golang.org/doc/install][Binary Installation Instructions]]
  - [[https://golang.org/doc/install/source][Source Installation Instructions]]

- [[https://golang.org/pkg][Go Packages Source Code]]

* Tutorial
The examples here,  and indeed in the  whole book, are aimed at  tasks that you
might have to  do in the real world.   In this chapter we’ll try to  give you a
taste of  the diversity of  programs that one might  write in Go,  ranging from
simple file processing and a bit of graphics to concurrent Internet clients and
servers.

When you’re learning  a new language, there’s a natural  tendency to write code
as you would have written it in a  language you already know.  Be aware of this
bias  as you  learn Go  and try  to avoid  it.  We’ve  tried to  illustrate and
explain how  to write  good Go, so  use the  code here as  a guide  when you’re
writing your own.

** Hello World

#+caption:gopl.io/ch1/helloworld.go
#+name:HelloWorld
#+begin_src go :tangle ./resources/src/go/ch1/helloworld.go :mkdirp yes :comments both
  package main

  import "fmt"

  func main() {
	  fmt.Println("Hello, world!")
  }
#+end_src

#+caption:lisp/ch1/helloworld.lisp
#+name:HelloWorldCL
#+begin_src lisp :tangle ./resources/src/cl/ch1/helloworld.lisp :mkdirp yes :comments both
  (princ "Hello, world!")
#+end_src

#+texinfo:@heading Lisp Printing
- ~write~ is the general entry point to the Lisp printer.
- ~prin1~ produces output suitable for input to ~read~.
- ~princ~ is just like ~prin1~ except that the output has no escape characters.
- The general  rule is  that output from  ~princ~ is intended  to look  good to
  people, while output from ~prin1~ is intended  to be acceptable to ~read~.
- ~print~  is just like ~prin1~ except that the printed representation of
  =object= is preceded by a newline and followed by a space.
- ~pprint~ is just  like ~print~ except that the trailing  space is omitted and
  =object= is printed with the  =*print-pretty*= flag non-nil to produce pretty
  output.

#+texinfo:@heading Go is a Compiled Language
#+texinfo:@subheading The Go Toolchain and Compilation
#+cindex:Go toolchain
#+pindex:go command

The Go toolchain  converts a source program  and the things it  depends on into
instructions in  the native machine  language of  a computer.  These  tools are
accessed through a single command called ~go~ that has a number of subcommands.

#+texinfo:@subheading @command{go run}
#+pindex:run command

The simplest of  these subcommands is ~go run~, which  compiles the source code
from  one  or more  source  files  whose names  end  in  ~.go~, links  it  with
libraries, then runs the resulting executable file.

: $ go run helloworld.go
: => Hello, World!

#+texinfo:@subheading @command{go build}
#+pindex:build command

If the program is  more than a one-shot experiment, it’s  likely that you would
want to  compile it once and  save the compiled  result for later use.  That is
done with ~go build~:

: $ go build helloworld.go
: $ ./helloworld
: => Hello, World!

This creates  an executable binary file  called ~helloworld~ that can  be run any
time without further processing.

#+texinfo:@heading  Packages
#+cindex:packages

Go  code is  organized into  @@texinfo:@dfn{packages}@@, which  are similar  to
libraries or modules in other languages.

A package consists of one or more ~.go~ source files in a single directory that
define  what  the  package  does.

#+texinfo:@subheading Package Declaration
#+cindex:package declaration
Each  source  file  begins  with a  @@texinfo:@dfn{package  declaration},  here
~package main~,  that states which package  the file belongs to,  followed by a
list  of other  packages that  it  imports, and  then the  declarations of  the
program that are stored in that file.

#+texinfo:@subheading Go Standard Library Packages
#+cindex:standard library packages
The Go standard library  has over 100 packages for common  tasks like
- input and output,
- sorting, and
- text manipulation.

#+texinfo:@subheading @command{fmt} Package and @command{Println}
#+cindex:fmt package
For  instance, the  ~fmt~  package contains  functions  for printing  formatted
output and scanning  input.  ~Println~ is one of the  basic output functions in
~fmt~;  it prints  one or  more  values, separated  by spaces,  with a  newline
character at the end so that the values appear as a single line of output.

#+texinfo:@subheading Package @command{main}
#+cindex:package main
Package ~main~ is  special.  It defines a standalone executable  program, not a
library.   Within package  ~main~ the  function ~main~  is also  special---it’s
where  execution of  the  program begins.   Whatever ~main~  does  is what  the
program does.   Of course, ~main~  will normally  call upon functions  in other
packages to do much of the work, such as the function ~fmt.Println~.

#+texinfo:@subheading @command{Import} Declaration
#+cindex:import declaration
We must tell the compiler what packages  are needed by this source file; that’s
the role of the ~import~ declaration that follows the package declaration.  The
"hello, world" program uses only one  function from one other package, but most
programs will import more packages.

You must import exactly  the packages you need.  A program  will not compile if
there  are missing  imports  or if  there are  unnecessary  ones.  This  strict
requirement  prevents  references  to  unused  packages  from  accumulating  as
programs evolve.

#+texinfo:@heading Program Declarations
#+cindex:program declarations
The ~import~ declarations must follow the ~package~ declaration.  After that, a
program consists  of the declarations  of functions, variables,  constants, and
types (introduced by the keywords ~func~,  ~var~, ~const~, and ~type~); for the
most part, the order of declarations does not matter.  This program is about as
short as possible since it declares only one function, which in turn calls only
one other function. To save space, we will sometimes not show the ~package~ and
~import~ declarations when presenting examples, but they are in the source file
and must be there to compile the code.

#+texinfo:@subheading Function Declaration
#+cindex:function declaration
A  function  declaration consists  of  the  keyword  ~func~,  the name  of  the
function, a parameter list (empty for ~main~), a result list (also empty here),
and  the   body  of   the  function---the  statements   that  define   what  it
does—--enclosed in braces.  We’ll take a closer look at functions in Chapter 5.

#+texinfo:@subheading Declaration Syntax
#+cindex:syntax
Go  does not  require semicolons  at the  ends of  statements or  declarations,
except  where  two or  more  appear  on the  same  line.   In effect,  newlines
following certain tokens  are converted into semicolons, so  where newlines are
placed matters to proper parsing of Go code.

- For instance, the opening brace ={= of  the function must be on the same line
  as the  end of the ~func~  declaration, not on a  line by itself, and  in the
  expression =x  + y=,  a newline  is permitted  after but  not before  the =+=
  operator.

#+texinfo:@heading Go Code Formatting
#+cindex:code formatting

#+texinfo:@subheading @command{gofmt} Tool and @command{fmt} Subcommand
#+pindex:gofmt tool
#+pindex:fmt subcommand
Go takes  a strong stance on  code formatting.  The ~gofmt~  tool rewrites code
into the standard format, and the go tool’s ~fmt~ subcommand applies ~gofmt~ to
all the files in the specified package, or the ones in the current directory by
default.

All Go source files  in the book have been run through  ~gofmt~, and you should
get into the habit  of doing the same for your own  code.  Declaring a standard
format by  fiat eliminates  a lot  of pointless debate  about trivia  and, more
importantly, enables  a variety of  automated source code  transformations that
would be infeasible if arbitrary formatting were allowed.

Many text editors can  be configured to run ~gofmt~ each time  you save a file,
so  that your  source  code  is always  properly  formatted.

#+texinfo:@subheading @command{goimports}
#+pindex:goimports tool
A related tool, ~goimports~, additionally  manages the insertion and removal of
~import~ declarations as  needed.  It is not part of  the standard distribution
but you can obtain it with this command:

: $ go get golang.org/x/tools/cmd/goimports

** Command-Line Arguments

#+texinfo:@heading @command{os.Args} Variable
#+vindex:os.Args
#+vindex:Args
#+vindex:os package

The  ~os~ package  provides functions  and other  values for  dealing with  the
operating system in a platform-independent fashion.

*Command-line arguments* are available to a  program in a variable named ~Args~
that is  part of  the ~os~  package; thus  its name  anywhere outside  the ~os~
package is ~os.Args~.

#+texinfo:@subheading Slices

The variable ~os.Args~ is a /slice/ of strings.  @@texinfo:@dfn{Slices}@@ are a
fundamental notion in Go, and we’ll talk  a lot more about them soon.  For now,
think of  a slice  as
- a  dynamically  sized  sequence  ~s~ of  =array=  elements  where  individual
  elements can be accessed as ~s[i]~ and a contiguous subsequence as ~s[m:n]~.
- The number of elements is given by ~len(s)~.
- As in  most other programming  languages, all  indexing in Go  uses half-open
  intervals  that include  the first  index but  exclude the  last, because  it
  simplifies logic.
- For example, the slice  ~s[m:n]~, where =0 ≤ m ≤ n  ≤ len(s)=, contains =n-m=
  elements.


#+texinfo:@subheading Elements of Slice
1. The first  element of ~os.Args~, ~os.Args[0]~, is the  name of the *command*
   itself;

2. the  other elements are the  *arguments* that were presented  to the program
   when it started execution.

3.  A  *slice expression* of  the form ~s[m:n]~ yields  a slice that  refers to
   elements =m= through =n-1=, so the elements we need for our next example are
   those in the slice ~os.Args[1:len(os.Args)]~.  If  =m= or =n= is omitted, it
   defaults to  0 or ~len(s)~  respectively, so  we can abbreviate  the desired
   slice as ~os.Args[1:]~.

*** Echo1
Here’s  an  implementation  of  the  Unix  ~echo~  command,  which  prints  its
command-line arguments  on a single line.   It imports two packages,  which are
given as a parenthesized list  rather than as individual ~import~ declarations.
Either form is legal,  but conventionally the list form is  used.  The order of
imports  doesn’t  matter;  the  ~gofmt~  tool  sorts  the  package  names  into
alphabetical order.

#+caption:gopl.io/ch1/echo1
#+name:Echo1
#+begin_src go :tangle ./resources/src/go/ch1/echo1.go :mkdirp yes

  /* Echo1 prints its command-line arguments. */
  package main

  import (
	  "fmt"
	  "os"
  )

  func main() {
	  var s, sep string
	  for i := 1; i < len(os.Args); i++ {
		  s += sep + os.Args[i]
		  sep = " "
	  }
	  fmt.Println(s)
  }
#+end_src

The ~echo~ program could have printed its output in a loop one piece at a time,
but this version instead builds up a string by repeatedly appending new text to
the end.  The string ~s~ starts life  empty, that is, with value =""=, and each
trip through the loop adds some text  to it; after the first iteration, a space
is also inserted so that when the  loop is finished, there is one space between
each argument.  This is a quadratic process  that could be costly if the number
of arguments is large, but for ~echo~, that’s unlikely.  We’ll show a number of
improved versions of  ~echo~ in this chapter  and the next that  will deal with
any real inefficiency.

#+texinfo:@subheading Comments
Comments begin  with =//=.   All text from  a =//=  to the end  of the  line is
commentary for programmers  and is ignored by the compiler.   By convention, we
describe  each  package  in  a  comment  immediately  preceding  its  ~package~
declaration;  for a  ~main~  package,  this comment  is  one  or more  complete
sentences that describe the program as a whole.

#+texinfo:@subheading @command{var} Declaration and Initialization
#+cindex:var declaration
#+cindex:initialization
#+cindex:explicit initialization
#+cindex:implicit initialization
#+cindex:zero value
The ~var~ declaration  declares two variables ~s~ and ~sep~,  of type =string=.

- A variable  can be  *initialized* as  part of  its declaration.
- If it is not *explicitly initialized*,  it is *implicitly initialized* to the
  *zero value* for its type, which is
  - 0 for numeric types and
  - the empty string =""= for strings.
- Thus in this example, the declaration implicitly initializes =s= and =sep= to
  empty strings.

#+texinfo:@subheading Short Variable Declaration
#+cindex:short variable declaration
The *loop index variable* ~i~ is declared  in the first part of the =for= loop.
The =:==  symbol is part  of a *short  variable declaration*, a  statement that
declares one  or more variables and  gives them appropriate types  based on the
initializer values.

#+texinfo:@subheading Arithmetic and Logical Operators---Concatenation Operator
#+cindex:operators
#+cindex:concatenation
For  numbers, Go  provides the  usual arithmetic  and logical  operators.  When
applied to strings,  however, the =+= operator concatenates the  values, so the
expression

: sep + os.Args[i]

represents  the *concatenation*  of  the strings  ~sep~  and ~os.Args[i]~.

#+texinfo:@subheading Assignment Operators---Assignment Statements
#+cindex:assignment statement
The  statement we  used  in  the program,

: s += sep + os.Args[i]

is an *assignment statement* that concatenates  the old value of ~s~ with ~sep~
and ~os.Args[i]~ and assigns it back to ~s~; it is equivalent to

: s = s + sep + os.Args[i]

#+cindex:assignment operator
The  operator =+==  is an  *assignment  operator*.  Each  arithmetic and  logical
operator like =+= or =*= has a corresponding assignment operator.

#+texinfo:@subheading Increment and Decrement Statements
#+cindex:increment statement
#+cindex:decrement statement
The *increment  statement* =i++=  adds 1 to  ~i~; it’s equivalent  to ~i  += 1~
which is in turn equivalent to ~i = i + 1~.  There’s a corresponding *decrement
statement* =i--= that subtracts 1.

*NOTE:* These are  *statements*, not expressions as they are  in most langauges
in the =C= family, ~j = i++~ is  illegal and they are postfil only, so =--i= is
not legal either.

#+texinfo:@heading The @command{for} Loop
#+cindex:for loop
The ~for~ loop is  the *only* loop statement in Go.  It has  a number of forms,
one of which is illustrated here:

#+caption:For Loop
#+name:ForLoop
#+begin_src go
  for initialization; condition; post {
	  // zero or more statements
  }
#+end_src

,*Parentheses* are never used around the three components of a ~for~ loop.  The
,*braces* are  mandatory, however, and  the opening brace  must be on  the same
line as the post statement.

- initialization statement :: The optional *initialization statement* is
  executed before the loop starts.  If it  is present,  it must  be  a simple
  statement,  that is,  a short  variable declaration, an  increment or  assignment statement, or  a function  call.
- condition  statement ::  The  *condition*  is a  boolean  expression that  is
  evaluated at the beginning of each iteration  of the loop; if it evaluates to
  =true=, the statements controlled by the loop are executed.
- post statement   :: The *post  statement* is executed  after the body  of the
  loop, then the condition is evaluated again. The loop ends when the condition
  becomes false.

Any of these parts may be omitted.   If there is no initialization and no post,
the semicolons may also be omitted:

#+cindex:while loop
#+caption:While Loop
#+name:WhileLoop
#+begin_src go
  // a traditional "while" loop
  for condition {
	  // ...
  }
#+end_src

If the condition is omitted entirely in any of these forms, for example in

#+cindex:infinite loop
#+caption:Infinite Loop
#+name:InfiniteLoop
#+begin_src go
  // a traditional infinite loop
  for {
	  // ...
  }
#+end_src

#+cindex:break statement
#+cindex:return statement
the loop is infinite, though loops of this form may be terminated in some other
way, like a ~break~ or ~return~ statement.

**** CL Echo1
CCL can be run directly from a terminal prompt.  CCL needs to know where the
~ccl~ directory is, and uses the environment variable =CCL_DEFAULT_DIRECTORY=
to locate it, i.e.
: export CCL_DEFAULT_DIRECTORY=/path/to/ccl
A  script named  =$CCL_DEFAULT_DIRECTORY/scripts/ccl= can  be placed  into your
path whose purpose is to make sure  this default directory is properly set, and
to invoke the ~ccl~ binary.

CCL has  a number of command-line  options, including =-e, --eval=,  which will
execute some  code.  Any arguments  following the pseudo-argument =--=  are not
processed,   and   are    made   available   to   Lisp   as    the   value   of
=*unprocessed-command-line-arguments*=.

The easiest way to create a command-line  script is to run a shell script which
~exec~'s a call  to the ~ccl~ binary  with one or more  =--eval= arguments (the
last  of  which  should  be  the   quit  command  ~(quit)~),  followed  by  the
pseudo-element =--= and the command-line arguments =$@=.

#+caption:cl/ch1/echo1
#+name:CLEcho1
#+header: :shebang "#!/usr/bin/env bash"
#+header: :cmdline a b c
#+header: :results output
#+begin_src sh :tangle ./resources/src/cl/ch1/echo1.sh :mkdirp yes
  exec ccl --eval '(let ((args *unprocessed-command-line-arguments*))
		     (pprint args)
		     (do ((a args (cdr a))
			  (s "" (concatenate '\''string s (car a))))
			((null a) (pprint s))))' \
	   --eval '(quit)' \
	   -- "$@"
#+end_src

#+RESULTS: CLEcho1
: 
: ("a" "b" "c")
: "abc"

*** Echo2

#+texinfo:@heading Range Loop
#+cindex:range operator
Another form of  the ~for~ loop iterates  over a *range of values*  from a data
type like  a string  or a  slice.  To  illustrate, here’s  a second  version of
~echo~:

#+caption:gopl.io/ch1/echo2
#+name:Echo2
#+begin_src go :tangle ./resources/src/go/ch1/echo2.go :mkdirp yes :comments both
  // Echo2 prints its command-line arguments. package main
  package main

  import (
	  "fmt"
	  "os"
  )

  func main() {
	  s, sep := "", ""
	  for _, arg := range os.Args[1:] {
		  s += sep + arg
		  sep = " "
	  }
	  fmt.Println(s)
  }
#+end_src

In each iteration of the loop, ~range~ produces a pair of values: the index and
the value  of the element at  that index.  In  this example, we don’t  need the
index,  but the  syntax of  a range  loop  requires that  if we  deal with  the
element, we  must deal with  the index  too.  One idea  would be to  assign the
index to an obviously temporary variable  like ~temp~ and ignore its value, but
Go  does  not  permit  unused  local  variables, so  this  would  result  in  a
compilation error.

#+texinfo:@subheading The Blank Identifier
#+cindex:blank identifier
The solution  is to use  the @@texinfo:@dfn{blank identifier}@@, whose  name is
=_= (that is, an underscore).  The blank identifier may be used whenever syntax
requires a variable name but program logic does not, for instance to discard an
unwanted  loop  index  when  we  require  only  the  element  value.   Most  Go
programmers would  likely use ~range~  and =_= to  write the ~echo~  program as
above, since  the indexing over ~os.Args~  is implicit, not explicit,  and thus
easier to get right.

#+texinfo:@subheading Declaring String Variables
This version of the program uses  a *short variable declaration* to declare and
initialize ~s~ and ~sep~, but we could equally well have declared the variables
separately.  There are several ways to declare a string variable; these are all
equivalent:

#+begin_src go
s := ""
var s string
var s = ""
var s string = ""
#+end_src

Why should  you prefer one  form to another?
1. The  first form, a  short variable declaration, is the  most compact, but it
   may be used only  within a function, not  for   package-level  variables.
2.  The second  form relies  on default  initialization to  the zero  value for
   strings, which is "".
3. The third form is rarely used except when declaring multiple variables.
4. The  fourth form is explicit  about the variable’s type,  which is redundant
   when it  is the same  as that  of the initial  value but necessary  in other
   cases where they are not of the same type.

#+begin_cartouche
In practice, you should generally use one of the first two forms, with explicit
initialization  to  say  that  the  initial value  is  important  and  implicit
initialization to say that the initial value doesn’t matter.
#+end_cartouche

*** Echo3
Each time  around the loop, the  string ~s~ gets completely  new contents.  The
=+== statement  makes a  new string  by concatenating the  old string,  a space
character, and the next argument, then assigns  the new string to ~s~.  The old
contents of ~s~ are no longer in  use, so they will be garbage-collected in due
course.

If the amount of  data involved is large, this could be  costly.  A simpler and
more efficient solution would be to  use the ~Join~ function from the ~strings~
package:
#+cindex:strings.Join function

#+caption:gopl.io/ch1/echo3
#+name:Echo3
#+begin_src go :tangle ./resources/src/go/ch1/echo3.go :mkdirp yes :comments both
  // Print command-line arguments using strings.Join
  package main

  import (
	  "fmt"
	  "os"
	  "strings"
  )

  func main() {
	  fmt.Println(strings.Join(os.Args[1:], " "))
  }
#+end_src

Finally, if we don’t care about format but just want to see the values, perhaps
for debugging, we can let ~Println~ format the results for us:

: fmt.Println(os.Args[1:])

The output of this  statement is like what we would  get from ~strings.Join~, but
with surrounding brackets.  Any slice may be printed this way.

*** Exercises

**** Exercise 1.1
Modify the ~echo~  program to also print ~os.Args[0]~, the  name of the command
that invoked it.

#+caption:Ch1 Exercise 1.1
#+name:Exercise1.1
#+begin_src go :tangle ./resources/src/go/ch1/exercise1.1.go :mkdirp yes :comments both
  // Echo the name of the command that invokes this package.
  package main

  import (
	  "fmt"
	  "os"
	  "strings"
   )

  func main() {
	    fmt.Println(strings.Join(os.Args[0:], " "))
  }
#+end_src

**** Exercise 1.2
Modify the ~echo~ program to print the  index and value of each of its arguments,
one per line.

#+caption:Ch1 Exercise 1.2
#+name:Exercise1.2
#+begin_src go :tangle ./resources/src/go/ch1/exercise1.2.go :mkdirp yes :comments both
  // Echo the command-line arguments, and print the index and value of each argument
  // on a separate line
  package main

  import (
	  "fmt"
	  "os"
  )

  func main() {
	  for index, value := range os.Args[0:] {
		  fmt.Println(index, value)
	  }
  }
#+end_src

**** Exercise 1.3
Experiment to  measure the difference  in running time between  our potentially
inefficient  versions  and the  one  that  uses ~strings.Join~.   (Section  1.6
illustrates part  of the ~time~  package, and Section  11.4 shows how  to write
benchmark tests for systematic performance evaluation.)

* Program Structure
* Basic Data Types
* Composite Types
* Functions
* Methods
* Interfaces
* Goroutines and Channels
* Concurrency with Shared Variables
* Packages and Go Tool
* Testing
* Reflection
* Low-Leval Programming

* Writing Go in Emacs
:PROPERTIES:
:appendix: t
:Author:   Dominik Honnef
:END:
- [[https://honnef.co/posts/2013/03/writing_go_in_emacs/][Writing Go in Emacs]] Article

** Go-Mode
In this article, I will talk about go-mode for Emacs, its history and features,
as well as useful extensions to it.

I rewrote the mode  from scratch.  I took special care to build  it on top of a
solid foundation, making  use of Emacs’s parsing facilities, as  opposed to the
previous version  of the mode,  which implemented  its own parser.   Apart from
generally bug-free behavior,  this also allowed building a lot  of functions on
top of it.

** Obtaining Go-Mode
Golang no longer distributes ~go-mode~.

You can find ~go-mode~ on [[https://github.com/dominikh/go-mode.el][GitHub]].

** Installing Go-Mode
Obtain ~go-mode~ from GitHub and generate ~go-mode-load.el~

: M-x update-file-autoloads RET go-mode.el

Put both  ~go-mode.el~ and ~go-mode-load.el~  into a directory of  your choice,
add it to Emacs’s load paths via

: (add-to-list 'load-path "/place/where/you/put/it")
: (require 'go-mode-load)

This will install autoload entries and associate ~*.go~ files with ~go-mode~.

** Go-Mode Features
*** Reading Documentation
- ~godoc~ function :: you can invoke  the identically named Go tool from within
  Emacs  and  read package  documentation  in  a view-mode  buffer.  Additional
  feature: You can tab complete import paths.

- ~gofmt~ :: automatically formats your code to the one true coding style, used
  by every Go developer.

  In Emacs, there are two ways to use ~gofmt~.

  1. invoke ~gofmt~ manually with the identically named function ~gofmt~, which
     will patch the current buffer according to ~gofmt~.

  2.   use  a  before-save-hook  to  run  ~gofmt~ every  time  you  save  a  Go
     buffer.  Enabling that hook is as easy as doing:

     : (add-hook 'before-save-hook 'gofmt-before-save)

 - eldoc    ::    https://github.com/syohex/emacs-go-eldoc    provides    eldoc
   functionality for ~go-mode~.
*** Managing Imports
The new ~go-mode~ has three  functions for working with imports:

- ~go-import-add~ (=C-c   C-a)=  ::  will prompt  you for an import path (again
  supporting tab completion) and insert it  in the import block, creating it if
  necessary.   If an  import  already existed  but was  commented,  it will  be
  uncommented.  If prefixed with =C-u=, it will  ask you for an alias, too.  An
  annoying procedure  of moving  around and mental  context switching  has just
  been reduced to a keystroke.

- ~go-remove-unused-imports~ :: Instead  of offering a function  for removing a
  single import, ~go-mode~  will detect all unused imports and  delete them (or
  comment them) once you run ~go-remove-unused-imports~.   It is not bound to a
  key by default,  but you can bind  it yourself if you want  to.  Personally I
  have bound it to =C-c C-r=:

  : (add-hook 'go-mode-hook (lambda ()
  :    (local-set-key (kbd "C-c C-r") 'go-remove-unused-imports)))

- ~go-goto-imports~ :: If you  decide you want to look at  your imports or edit
  them manually, ~go-goto-imports~ will take you to them automatically, placing
  your cursor after the last import.  It isn’t bound to a key.

*** Navigating Code
~go-mode~ supports ~beginning-of-defun~ (=C-M-a=) and ~end-of-defun~ (=C-M-e=),
two  core  Emacs functions  for  navigating  between functions.   Additionally,
functions  such  as  ~narrow-to-defun~  and  ~mark-defun~  rely  on  these  two
functions.

You can also use ~Imenu~ to jump to specific function or type declarations.

**** Godef
~go-mode~  integrates with  ~godef~, an  amazing little  tool written  by Roger
Peppe.  ~godef~ is able to parse your code, and the code of other packages, and
the code of the  Go standard library, and can tell you  what exactly the symbol
you’re looking at means and where it has been defined.

Install ~godef~ with:

: go get code.google.com/p/rog-go/exp/cmd/godef

~go-mode~ makes use of this to  provide the two functions:
- ~godef-describe~ (=C-c C-d=) :: will tell you what you’re looking at
- ~godef-jump~ (=C-c  C-j=) ::  will  take you  to its definition.   This works
  across files,  packages and  into the standard  library, without  needing any
  tags.  And it has almost no measurable delay.

**** Interacting with the Playground
~go-mode~ integrates with the Playground.  It offers:

- ~go-play-buffer~
- ~go-play-region~
- ~go-download-play~

to send the current buffer or region to the Playground and store a link in your
kill ring and directly download a paste from the Playground into Emacs.

*** Syntax Checking
~FlyMake~ is Emacs’s solution to on-the-fly syntax checking.

- ~goflymake~ :: https://github.com/dougm/goflymake

 Doug MacEachern  wrote [[https://github.com/dougm/goflymake][goflymake]], which  consists of  a small Go  binary and
 some elisp  to integrate it with  Emacs.  Because Go compiles  blazingly fast,
 using ~goflymake~  doesn’t cause any  performance penalties.  Personally  I am
 letting ~FlyMake~ compile  my Go buffers every time I  insert a newline.  More
 conservative settings  would compile after a  certain amount of idle  time, or
 when saving the buffer.

- ~flymakego~ :: http://marmalade-repo.org/packages/flymake-go

  a more lightweight solution  that only uses ~gofmt~ and as  such is only able
  to catch syntax errors.  Unlike ~goflymake~,  however, it does not require an
  additional executable.

- ~flycheck~ ::  a modern replacement  for ~flymake~, which comes with built-in
  support for  Go.  In  addition to using  ~go build~ or  ~gofmt~, it  also has
  support for ~go vet~, ~golint~ and ~errcheck~.

*** Autocompletion
~gocode~, written by nsf, provides the kind of autocompletion.

Personally I recommend trying ~company-mode~ first.

- gopls  ::  https://github.com/golang/tools/tree/master/gopls the  official Go
  [[https://langserver.org][language server]]  developed by the Go  team.  It provides IDE  features to any
  LSP-compatible editor.

  - https://github.com/golang/tools/blob/master/gopls/doc/emacs.md

  To use  ~gopls~ with  Emacs, you  must first install  the ~gopls~  binary and
  ensure that the  directory containing the resulting binary  (either =$(go env
  GOBIN)= or  =$(go env  GOPATH)/bin)= is  in your PATH.   To use  ~gopls~ with
  Emacs,  you  must first  install  the  ~gopls~  binary  and ensure  that  the
  directory containing the resulting binary (either =$(go env GOBIN)= or =$(go
  env GOPATH)/bin)= is in your PATH.

*** Snippets
One of the more popular implementations of snippets for Emacs is YASnippet, and
it is YASnippet that I wrote a [[https://github.com/dominikh/yasnippet-go/tree/master/go-mode][small number of Go snippets for]].

- https://github.com/dominikh/yasnippet-go

*** Finding unchecked errors with go-errcheck
- ~go-errcheck~    ::     https://github.com/dominikh/go-errcheck.el offers the
  ~go-errcheck~ function, which will run  ~errcheck~ on the current package and
  report errors in a compilation buffer.

- ~errcheck~  :: https://github.com/kisielk/errcheck  a tool  written by  Kamil
  Kisiel for finding and reporting unchecked errors in your Go code.

  : go get -u github.com/kisielk/errcheck

  : errcheck github.com/kisielk/errcheck/testdata
  : errcheck ./...
  : errcheck all

  ~go-errcheck.el~   integrates   ~errcheck~   with  Emacs   by   providing   a
  ~go-errcheck~ command and customizable  variables to automatically pass flags
  to ~errcheck~.

*** Go Language Server
~Gopls~  is  the  official  language  server  protocol  (~lsp~)  implementation
provided by the  Go team.  It is  intended to replace the  existing third party
tools  for code  formatting  (~gofmt~), automatic  imports (~goimports~),  code
navigation  (~godef/guru~),  type  and function  descriptions  (~godoc/godef~),
error  checking,  auto  completion   (~gocode~),  variable  and  type  renaming
(~rename~), and more.  Once ~gopls~ is stable the older tools will no longer be
supported.

~Gopls~ is a supported backend for ~lsp-mode~. It will be used automatically by
~lsp-mode~ if ~gopls~ is  found in your =PATH=.  You can  install ~gopls~ via:

: go get golang.org/x/tools/gopls@latest

To enable ~lsp-mode~ for go buffers:

: (add-hook 'go-mode-hook 'lsp-deferred)

** Go Tools
- [[https://github.com/dominikh/go-tools][go-tools]]
- Staticcheck ::

  ~Staticcheck~ is a  state of the art linter for  the Go programming language.
  Using  static  analysis,  it  finds   bugs  and  performance  issues,  offers
  simplifications, and enforces style rules.

  - Staticcheck Website :: https://staticcheck.io/docs/

* Build Tools
:PROPERTIES:
:appendix: t
:custom_id: build-tools
:END:
** Makefile					:dependencies:env_vars:perl:
:PROPERTIES:
:appendix: t
:dependency1: make
:dependency2.0: AWS User account at https://aws.amazon.com
:dependency2.1: AWS cli v2 in PATH https://docs.aws.amazon.com/cli/index.html
:dependency2.2: See how to Install AWS CLI v2 at https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html
:dependency2.3: aws credentials: access token and secret access token stored in ~/.aws/credentials
:dependency2.4: AWS S3 buckets set up for serving a static web page
:dependency3: GitHub Account with personal access token stored in GITHUB_TOKEN
:dependency4: texinfo @6.7._
:dependency5: Emacs, Org-mode, Babel language 'shell' enabled
:env_var1: SYNC_ORG_TEMPLATE: holds the full path to this Template.org file
:env_var2: GITHUB_TOKEN: holds the GitHub personal access token
:env_var3: EDITOR: must hold a reference to a working emacsclient server
:env_var4: COLORS
:END:

#+pindex:Makefile
#+name:Makefile
#+header: :tangle Makefile
#+begin_src makefile

  ###############################################################################
  ### USER-DEPENDENT VARIABLES
  ### USE ENVIRONMENT VARIABLES WHENEVER POSSIBLE

  # NOTE: All environment variables need to be exported PRIOR to starting the
  # Emacs server as EDITOR in your shell startup files; otherwise, they will not
  # be available to Emacs.
  # When I moved from using Bash to Zsh, I inadvertently changed the order of
  # import, and started the Emacs server before importing, and caused a horrible
  # bug which caused the program to work on one computer but fail on another.

  # The absolute path to this Template file
  TEMPLATE := $(SYNC_ORG_TEMPLATE)


  ### TOOLS & RESOURCES
  # tools is a directory holding tangled scripts, such as cmprpl
  # resources is a directory holding static resources for the project
  # images is a directory holding jpg and png image files
  RESOURCES := resources
  TOOLS	:= $(RESOURCES)/tools
  IMAGES    := $(RESOURCES)/images
  CMPRPL    := $(TOOLS)/cmprpl

  # Use emacsclient as $EDITOR; make sure it is set in a shell startup file and
  # the server has been started.
  EMACS	:= $(EMACS)
  EDITOR	:= $(EDITOR)

  # User’s personal GitHub token for authentication to GitHub
  # DO NOT HARD-CODE THIS VALUE
  GITHUB_TOKEN := $(GITHUB_TOKEN)

  # The AWS Command Line Interface (AWS CLI) is an open source tool
  # that enables you to interact with AWS services using commands in
  # your command-line shell.  It must be present on your system.  Run the 'make'
  # command 'install-aws-cli' to install it if you do not have it.  Be sure to
  # run 'aws configure' after installing it.  This will place your AWS
  # credentials into ~/.aws/credentials.
  AWS := aws
  S3  := $(AWS) s3
  CFD := $(AWS) cloudfront

  ### END OF USER-DEPENDENT VARIABLES
  ###############################################################################
  ### MAKE-GENERATED VARIABLES

  ### PROJ AND ORG
  # ORG is the name of this Org file with extension .org
  # PROJ is the project name---the Org file name without extension.

  ### NOTE: there can be only one Org file in the project directory;
  # so far this has not been a problem, but it might be.

  PWD  := $(shell pwd)
  ORG  := $(shell ls *.org)
  PROJ := $(basename $(ORG))

  ### NOTE: S is needed only for the Template file because of the way it is nested
  # one level deep in the Templates GitHub repo, which uses the plural form
  # of Templates, whereas this file uses the singular form, Template.  So when
  # the homepage link is updated, the curl command must be told to use the plural
  # form.	 This is obviously a hack only for my own use and can be removed once
  # I clean up this anomaly.

  ifeq ($(PROJ),$(basename $(notdir $(TEMPLATE))))
  S := s
  endif

  # The AWS S3 bucket to use to store the html source file; it is found at the
  # key #+bucket towards the beginning of the file and should include the appropriate
  # suffix (.com, .net, .org, etc)
  BUCKET       := $(shell $(EDITOR) --eval \
		 '(with-current-buffer (find-file-noselect "$(ORG)") \
		    (save-excursion \
		      (goto-char (point-min)) \
		      (re-search-forward "^\#[+]bucket:\\(.*\\)$$" nil t) \
		      (match-string-no-properties 1)))')
  S3_BUCKET    := s3://$(BUCKET)

  # Buckets set up to serve static web sites from S3 can use either http
  # or https protocols; some  http protocols will automatically redirect
  # to https;  however, some only use  http. I would like  to accomodate
  # both, and  so this code  finds the url's  that are in  my Cloudfront
  # account, which presumably will serve https.  If the url is not here,
  # then this must be set up to serve http instead.
  HTTP_S := $(shell $(CFD) list-distributions | perl -MJSON::PP -e \
	  '$$/=""; \
	   my @urls = (); \
	   my $$json=JSON::PP->new->decode(<STDIN>); \
	   for my $$item ( @{$$json->{"DistributionList"}{"Items"}} ) { \
		  push @urls, @{$$item->{"Aliases"}{"Items"}}; \
	   } \
	  my $$found = grep { /'$(BUCKET)'/ } @urls; \
	  print "http", ($$found ? "s" : "");')

  HTTPS_BUCKET := https://$(BUCKET)

  ### DIR, SRC
  # DIR is the .info name found at '#+texinfo_filename:<DIR>.info' (at
  # the bottom of this file in the export configuration settings)
  # without its extension, used as the INFO filename and the name of the
  # HTML export directory; this code uses the lowercased PROJ name if
  # there is no '#+texinfo_filename'.
  # SRC is HTML directory based upon the DIR name

  #DIR := $(shell $(EDITOR) --eval \
  #	'(with-current-buffer (find-file-noselect "$(ORG)") \
  #		(save-excursion \
  #		(goto-char (point-min)) \
  #		(re-search-forward "^\#[+]\\(?:texinfo_filename\\|TEXINFO_FILENAME\\):\\(.*\\).info$$" nil t) \
  #		(match-string-no-properties 1)))')

  DIR := $(shell sed -E -n "/^\#\+texinfo_filename/s/^.*:(.*)\.info$$/\1/p" $(ORG))
  ifeq ($(DIR),$(EMPTY))
	  DIR := $(shell echo $(PROJ) | tr "[:upper:]" "[:lower:]")
  endif

  SRC := $(DIR)/

  ### VERS: v1.2.34/
  # VERS is the version number of this Org document.
  # When sync is run after the version number has been updated, then VERS
  # picks up the newly-changed value.  VERS used to be staticly imbedded
  # when the Makefile was tangled, but it needs to be dynamic for
  # development.

  # QUERY: should this number be formatted like this, or should it be just the numbers?
  # The reason it includes them is the S3PROJ obtains the name from the S3 bucket, and
  # it includes them.  But it only includes them because I have made it so.  Not a good
  # reason just by itself.  The ending slash is not actually a part of the version, but
  # comes from the way the 'aws2 ls' command returns its values.	So VERS should probably
  # not include the trailing slash, although it doesn’t hurt anything.

  VERS := v$(shell $(EDITOR) --eval \
	  '(with-current-buffer (find-file-noselect "$(ORG)") \
		  (save-excursion \
		    (goto-char (point-min)) \
		    (re-search-forward "^\#[+]\\(?:macro\\|MACRO\\):version Version \\(\\(?:[[:digit:]]+[.]?\\)\\{3\\}\\)") \
		    (match-string-no-properties 1)))')/

  ### AWS
  # PROJ_LIST contains the list of projects currently uploaded to
  # the S3 bucket; each item contains the name of the project and its
  # current version.

  # Created function using elisp instead of the shell.
  # This variable contains an elisp list of strings of the form '("proj1-v1.2.3/" "proj2-v4.5.6/" ...)'
  # However, when it prints to the shell, the quotes are lost.
  # Need to make sure elisp's variable 'exec-path contains the proper $PATH instead of adding to 'exec-path.

  PROJ_LIST := $(shell $(EDITOR) --eval \
	  "(progn \
		  (require (quote seq)) (add-to-list (quote exec-path) (quote \"/usr/local/bin\")) \
		  (seq-map (lambda (s) (replace-regexp-in-string \"^\s+PRE \" \"\" s)) \
			  (seq-filter (lambda (s) (string-match-p (regexp-quote \" PRE \") s)) \
			  (process-lines \"$(AWS)\" \"s3\" \"ls\" \"$(S3_BUCKET)\"))))")

  ### S3PROJ
  # The name of the current project as obtained from S3: 'proj-v1.2.34/'
  # If there is no current project in the S3 bucket, then assign a value equal to
  # the Org project and version instead.  It is set to the project if found, and
  # NO if not found, then updated in the ifeq block below.
  S3PROJ := $(shell $(EDITOR) --eval \
		  '(let ((proj (seq-find (lambda (s) (string-match-p "$(DIR)" s)) (quote $(PROJ_LIST))))) \
		     (or proj (quote NO)))')

  ### PROJINS3
  # is used by make sync; this allows the index.html file to be generated the first
  # time the project is synced.  It is set to NO if this project is not currently in an
  # S3 bucket, and it is set to YES if it is.
  PROJINS3 :=

  ### S3VERS
  # The version of this project currently installed in the S3 bucket: 'v1.2.34/'
  # If there is no current version in the S3 bucket, then assign the version from
  # this Org file instead.
  S3VERS   :=

  # Update S3PROJ, S3VERS, and PROJINS3
  ifeq ($(S3PROJ), NO)
	  S3PROJ := $(DIR)-$(VERS)
	  S3VERS := $(VERS)
	  PROJINS3 := NO
  else
	  S3VERS := $(subst $(DIR)-,,$(S3PROJ))
	  PROJINS3 := YES
  endif

  ### GITHUB
  # USER is the current user's GitHub login name.

  # The user name used to be statically embedded into the Makefile
  # during tangle, but in an effort to make the Makefile dynamically
  # indepedent, dynamic code has replaced the static code.  The code
  # that placed the static name in the Makefile was a 'node' script that
  # ran in a separate Org process during tangle.	An unfortunate fact of
  # 'make' is that 'make' strips the quote marks from the string
  # obtained from the 'curl' command when the 'make shell' command
  # returns the string.	 This makes the string malformed JSON and
  # unparsable by most JSON parsers, including 'node’.	However,
  # 'perl'’s core module JSON::PP (but not JSON::XS) has facilities to
  # parse very malformed JSON strings.	Therefore, this dynamic code
  # uses 'perl' and the core module JSON::PP to parse the 'curl' string
  # into a 'perl' JSON object which can return the login name.	This
  # code should work with any version of 'perl' without having to
  # install any modules.

  USER	:= $(shell \
	    curl -sH "Authorization: token $(GITHUB_TOKEN)" https://api.github.com/user \
	    | \
	    perl -MJSON::PP -e \
		'$$/ = ""; \
		 my $$json = JSON::PP->new->loose->allow_barekey->decode(<STDIN>); \
		 print $$json->{login};' \
	    )
  SAVE		:= resources

  ### TEXINFO
  TEXI		:= $(PROJ).texi
  INFO		:= $(DIR).info
  INFOTN		:= $(shell $(EDITOR) --eval "(file-truename \"$(INFO)\")")
  PDF		:= $(PROJ).pdf
  INDEX		:= index.html
  HTML		:= $(DIR)/$(INDEX)
  DIR_OLD		:= $(DIR)-old

  ### AWS S3
  DST_OLD		:= $(S3_BUCKET)/$(S3PROJ)
  DST_NEW		:= $(S3_BUCKET)/$(DIR)-$(VERS)
  EXCL_INCL		:= --exclude "*" --include "*.html"
  INCL_IMAGES	:= --exclude "*" --include "*.jpg" --include "*.png"
  GRANTS		:= --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers
  S3SYNC		:= $(S3) sync --delete $(EXCL_INCL) $(SRC) $(DST_OLD) $(GRANTS)
  S3MOVE		:= $(S3) mv --recursive $(DST_OLD) $(DST_NEW) $(GRANTS)
  S3COPY		:= $(S3) cp $(INDEX) $(S3_BUCKET) $(GRANTS)
  S3REMOVE		:= $(S3) rm $(S3_BUCKET)/$(S3PROJ) --recursive
  S3IMAGESYNC	:= $(S3) sync $(INCL_IMAGES) $(IMAGES) $(S3_BUCKET)/$(IMAGES) $(GRANTS)

  ###############################################################################

  default: check texi info html pdf

  PHONY: default all check values boot \
	    texi info html pdf \
	    open-org open-texi open-html open-pdf \
	    clean dist-clean wiped-clean \
	    help sync update delete-proj \
	    install-aws-cli \
	    index-html upload-index-html

  values: check
	    @printf "$${BLUE}Values...$${CLEAR}\n"
	    @echo TEMPLATE:	$(TEMPLATE)
	    @echo EDITOR:	$(EDITOR)
	    @echo USER:		$(USER)
	    @echo PWD:		$(PWD)
	    @echo ORG:		$(ORG)
	    @echo TEXI:		$(TEXI)
	    @echo INFO:		$(INFO)
	    @ECHO INFOTN:	$(INFOTN)
	    @echo BUCKET:	$(BUCKET)
	    @echo PROJ:		$(PROJ) $S
	    @echo S3_BUCKET:	$(S3_BUCKET)
	    @echo HTTP_S:	$(HTTP_S)
	    @echo HTTPS_BUCKET:	$(HTTPS_BUCKET)
	    @echo VERS:		$(VERS)
	    @echo S3PROJ:	$(S3PROJ)
	    @echo S3VERS:	$(S3VERS)
	    @echo DIR:		$(DIR)
	    @echo DIR_OLD:	$(DIR_OLD)
	    @echo SRC:		$(SRC)
	    @echo DST_OLD:	$(DST_OLD)
	    @echo DST_NEW:	$(DST_NEW)
	    @echo PROJ_LIST:	"$(PROJ_LIST)"
	    @echo PROJINS3:	$(PROJINS3)

  check:
	    @printf "$${BLUE}Checking dependencies...$${CLEAR}\n"

	    @[[ -z $(BUCKET) ]] && \
	       { printf "$${RED}$(BUCKET) $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}BUCKET: $${GREEN}$(BUCKET)$${CLEAR}\n";

	    @[[ -z $${GITHUB_TOKEN} ]] && \
	       { printf "$${RED}GITHUB_TOKEN $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}GITHUB_TOKEN: $${GREEN}SET$${CLEAR}\n";

	    @[[ (-d ~/.aws) && (-f ~/.aws/credentials) && (-f ~/.aws/config) ]] && \
	       printf "$${CYAN}AWS credentials and config: $${GREEN}SET$${CLEAR}\n" || \
	       { printf "$${RED}~/.aws 'credentials' and 'config' must be set.$${CLEAR}\n"; exit 1; }

	    @[[ "$(shell $(EDITOR) --eval '(member (quote texinfo) org-export-backends)')" = "(texinfo)" ]] && \
		  printf "$${CYAN}Texinfo backend: $${GREEN}INSTALLED.$${CLEAR}\n" || \
		  { printf "$${YELLOW}Texinfo backend:$${CLEAR} $${RED}NOT INSTALLED; it must be installed.$${CLEAR}\n"; exit 1; }

	    @[[ $(shell $(EDITOR) --eval '(symbol-value org-confirm-babel-evaluate)') == "t" ]] && \
		  { printf "$${YELLOW}org-confirm-babel-evaluate:$${CLEAR} $${RED}T; set to NIL.$${CLEAR}\n"; exit 1; } || \
		  printf "$${CYAN}org-confirm-babel-evaluate: $${GREEN}OFF.$${CLEAR}\n\n"

  open-org: $(ORG)
	    @$(EDITOR) -n $(ORG)
  $(ORG):
	    @echo 'THERE IS NO $(ORG) FILE!!!'
	    exit 1

  texi: $(TEXI)
  $(TEXI): $(ORG)
	   @echo Making TEXI...
	   @$(EDITOR) -u --eval \
		  "(with-current-buffer (find-file-noselect \"$(ORG)\" t) \
			  (save-excursion \
			  (org-texinfo-export-to-texinfo)))"
	   @echo Done making TEXI.
  open-texi: texi
	   @$(EDITOR) -n $(TEXI)

  info: $(INFO)
  $(INFO): $(TEXI)
	   @echo Making INFO...
	   @makeinfo -o $(INFO) $(TEXI)
	   @$(EDITOR) -u -eval \
		  "(when (get-buffer \"$(INFO)\") \
			  (with-current-buffer (get-buffer \"$(INFO)\") \
				  (revert-buffer t t t)))"
	   @echo Done making INFO.

  open-info: info
	   @$(EDITOR) -u -eval \
		  "(if (get-buffer \"*info*\") \
			  (with-current-buffer (get-buffer \"*info*\") \
				(when (not (string= \"(symbol-value (quote Info-current-file))\" \"$(INFOTN)\")) \
					(info \"$(INFOTN)\")) \
				(revert-buffer t t t)) \
		      (info \"$(INFOTN)\"))"

  html: $(HTML)
  $(HTML): $(TEXI)
	   @echo Making HTML INFO..
	   @makeinfo --html -o $(DIR) $(TEXI)
	   @echo Done making HTML.
	   $(CMPRPL) $(DIR) $(DIR_OLD)
  open-html: html
	   @open $(HTML)

  # If pdftexi2dvi produces an error, it may still produce a viable PDF;
  # therefore, use --tidy.  If it produces an error, try to link the PDF;
  # if it does not produce an error, the PDF will be added to the top dir
  # and there will be no attempt to link.
  pdf:	$(PDF)
  $(PDF): $(TEXI)
	  @echo Making PDF INFO...
	  @-pdftexi2dvi --quiet --build=tidy $(TEXI) || ln -s $(PROJ).t2d/pdf/build/$(PDF) $(PDF)
	  @echo Done making PDF.
  open-pdf:pdf
	   @open $(PDF)

  tangle: $(ORG)
	      @$(EDITOR) -u --eval "(org-babel-tangle)"
	      @echo Done tangling

  sync:   $(HTML)
	  @echo Syncing version $(VERS) onto $(S3VERS)...
	  $(S3SYNC)
	  $(S3IMAGESYNC)
	  @echo Done syncing.
	  [[ $(VERS) != $(S3VERS) ]] && { echo Moving...; $(S3MOVE); echo Done moving.;  make homepage; } || :
	  [[ $(PROJINS3) = "NO" ]] && make homepage || :

  # This is a target-specific variable for updating the “description”
  # key on the GitHub repo page with the current version number.  It
  # first makes a curl call to the GitHub project repo, finds the
  # “description” line, pulls out the description only (leaving the old
  # version) and then prints the value with the current version number.
  # This value is used by the “homepage:” target in the PATCH call.
  # This method is arguably harder to code but faster to run than using
  # Perl with the JSON::PP module.

  homepage: description = $(shell \
	  curl -s \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S | \
		  (perl -ne 'if (/^\s*\"description\":\s*\"(.*): v(?:(?:[[:digit:]]+[.]?){3})/) {print $$1}'))

  ### NOTE the use of the S variable at the end of PROJ; this is to handle
  # the singular case of the GitHub repo using the plural form, Templates
  # whereas the the Template.org file uses the singular form.
  homepage: $(ORG) upload-index-html
	    @echo Updating homepage...
	    @echo DESCRIPTION: $(description)
	    @echo VERS: $(VERS)
	    @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Content-Type: application/json" \
		  -X PATCH \
		  -d "{\"homepage\":\"$(HTTPS_BUCKET)/$(DIR)-$(VERS)\",\
		       \"description\":\"$(description): $(VERS)\"}" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	    @echo Done updating homepage.

  delete-proj:
	  @echo Deleting project $(PROJ)...
	  @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Accept: application/vnd.github.v3+json" \
		  -X DELETE \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	  @$(S3REMOVE)
	  @make dist-clean
	  @make upload-index-html
	  @$(EDITOR) -u --eval "(kill-buffer \"$(ORG)\")"
	  @rm -rf "../$(PROJ)"
	  @echo Done deleting project.

  index-html: $(INDEX)
  $(INDEX): $(ORG)
	  @echo making index.html...
	  $(EDITOR) --eval \
	  "(with-current-buffer (find-file-noselect \"$(ORG)\") \
		  (save-excursion \
		    (org-link-search \"#project-index-title\") \
		    (org-export-to-file (quote html) \"index.html\" nil t)))"
	  @echo Done making index.html.

  upload-index-html: $(INDEX)
	   @echo Uploading index.html...
	   $(S3COPY)
	   @echo Done uploading index.html

  install-aws-cli:
	    curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg" && \
	    sudo installer -pkg AWSCLIV2.pkg -target / && \
	    which aws && aws --version
	    rm -rf AWSCLIV2.pkg

  clean:
	  @echo Cleaning...
	    -@rm *~ 2>/dev/null
	    -@for file in *.??*; \
	    do \
		    ext=$${file#$(PROJ).}; \
		    [[ ! $${ext} =~ org|texi|info|pdf|html ]] && rm -rv $${file}; \
	    done

  dist-clean: clean
	  @echo Dist Cleaning...
	    @${EDITOR} -u --eval \
	      "(kill-buffer \"$(ORG)\")"
	    -@rm -rf *.{texi*,info*,html*,pdf*} $(DIR) $(TOOLS)
	    -@for dir in *; \
		do \
		    [ -d $$dir -a $$dir != "$(DIR_OLD)" -a $$dir != $(SAVE) ] && \
		    rm -vr $$dir; \
		done

  wipe-clean: dist-clean
	  @echo Wipe Clean...
	    -@rm -rf Makefile Readme.md $(DIR_OLD)
	    @git checkout Makefile README.md

  git-ready: dist-clean
	    git checkout Makefile
	    git checkout README.md
	    git status

  help:
	    @echo '"make boot" tangles all of the files in Template'
	    @echo '"make default" makes the .texi file, the .info file, \
	    the html files, and the .pdf file.'
	    @echo

	    @echo '"make check" checks for prerequistes'
	    @echo '"make values" runs check and prints variable values'
	    @echo

	    @echo '"make texi" makes the .texi file'
	    @echo '"make info" makes the .info file'
	    @echo '"make html" makes the html distribution in a subdirectory'
	    @echo '"make pdf" makes the .pdf file'
	    @echo

	    @echo '"make open-org" opens the ORG program using emacsclient for editing'
	    @echo '"make open-texi" opens the .texi file using emacsclient for review'
	    @echo '"make open-html" opens the distribution index.html file \
	    in the default web browser'
	    @echo '"make open-pdf" opens the .pdf file'
	    @echo

	    @echo '"make sync" syncs the html files in the AWS S3 bucket BUCKET; \
	    you must have your AWS S3 bucket name in the env var AWS_S3_BUCKET; \
	    You must have your AWS credentials installed in ~/.aws/credentials'
	    @echo

	    @echo '"make install-aws-cli" installs the "aws cli v2" command-line tools'
	    @echo 'You also need to run "aws configure" and supply your Access Key and Secret Access Key'
	    @echo

	    @echo '"make clean" removes the .texi, .info, and backup files ("*~")'
	    @echo '"make dist-clean" cleans, removes the html distribution, \
	    and removes the build directory'
	    @echo '"make wipe-clean" wipes clean the directory, including old directories'
	    @echo

	    @echo '"make delete-proj" deletes the project from the file system, GitHub and AWS'

#+end_src

*** TODO Next
1. The CloudFront configuration needs to be updated recognize the new version
   directory that is created as part of the ~sync~ operation.

2. Update the GitHub HOME website link for each new sync operation.

3. Store on GitHub a version of each other format upon a sync operation (i.e.,
   the INFO and PDF versions)

** Compare Replace

#+begin_comment
The following source code tangles all files during an export operation. This is
to  make  sure  the  ~cmprpl~  source code  exists  in  the  ~resources/tools/~
directory before running  the Makefile target =html=. It also  makes sure there
is a Makefile on an initial export. The following code is not exported.
#+end_comment

#+name:tangle-org-file
#+header: :exports results :eval yes :results silent
#+begin_src emacs-lisp
(org-babel-tangle-file (buffer-file-name))
#+end_src

The  AWS ~sync~  command  relies  upon time  stamps  to  determine whether  two
programs are identical or not, as  well as content.  If two otherwise identical
files have  different time stamps,  ~sync~ will  assume they are  different and
will  process the  newer.   However, the  ~texinfo~  ~makeinfo --html~  command
produces all  new files even  if some files  (or most files)  remain unchanged.
This  means that  all files  will be  uploaded to  the AWS  S3 bucket  on every
iteration, even though the majority of the files are actually unchanged.

The ~cmprpl~  source code attempts to  resolve the issue of  identical exported
code having different  time stamps, thus defeating the benefit  provided by the
~aws2 s3 sync~ command uploading only changed files.

This program makes sure that a generated HTML directory exists: =$DIR_NEW=.  If
it doesn’t, then it is in an improper state and the program stops with an error
message.

The  program then  checks  if  an old  directory  exists,  =$DIR_OLD=.  If  one
doesn’t,  then one  is  created by  copying the  current  new directory.   This
provides a baseline  for comparisons going forward.  The program  exits at that
point. It is very important that  the =$DIR_OLD= directory not be deleted going
forward.

Given  that =$DIR_OLD=  exists, the  program then  loops through  all files  in
=$DIR_NEW= and  compares them  to the  files in =$DIR_OLD=.   If the  files are
identical, the =$DIR_OLD= file replaces the =$DIR_NEW= file while retaining the
old time stamp (using the ~-p~ option of ~cp~. If a file is different, then the
=$DIR_NEW= file  replaces the =$DIR_OLD=  file, thus giving it  updated content
and  an updated  time stamp.   If the  file does  not exist  in the  =$DIR_OLD=
directory, then it is added.

The  program then  loops through  all of  the files  in the  old directory  and
deletes  any that  do not  exist in  the new  directory.  Now  both directories
should be in sync.

#+caption:Compare Replace program
#+name:cmprpl
#+header: :mkdirp t
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src sh :tangle resources/tools/cmprpl
  [[ $# -eq 2 ]] || { echo "ERROR: Incorrect command line arguments"; exit 1; }
  DIR_NEW=$1
  DIR_OLD=$2

  [[ -d $DIR_NEW ]] || { echo "ERROR: $DIR_NEW does not exist"; exit 1; }
  [[ -d $DIR_OLD ]] || { echo "CREATING: $DIR_OLD does not exist"; cp -a $DIR_NEW $DIR_OLD; exit 0; }

  for newfile in $DIR_NEW/*
  do
      oldfile=$DIR_OLD/$(basename $newfile)
      if [[ -e $oldfile ]]
      then
	 if cmp -s $newfile $oldfile
	 then
	     printf "${GREEN}copying OLD to NEW${CLEAR}: "
	     cp -vp $oldfile $newfile
	 else
	     printf "${PURPLE}copying NEW to OLD${CLEAR}: "
	     cp -vp $newfile $oldfile
	 fi
      else
	  printf "${BLUE}creating NEW in OLD${CLEAR}: "
	  cp -vp $newfile $oldfile
      fi
  done

  for oldfile in $DIR_OLD/*
  do
      newfile=$DIR_NEW/$(basename $oldfile)
      if [[ ! -e $newfile ]]
      then
	  printf "${RED}removing OLD${CLEAR}: "
	  rm -v $oldfile
      fi
  done
#+end_src


** Update Utility Commands
*** Get Parsed Org Tree
This function looks for an Org file in the present working directory, and if it
finds one returns  a parsed tree using  ~org-element-parse-buffer~.  It returns
=nil= if there is no Org file or if the found file is not in ~org-mode~.

#+name:get-parsed-org-tree
#+header: :results silent
#+begin_src emacs-lisp
(defun get-parsed-org-tree (&optional org-dir)
  "This function takes an optional directory name, changes to
that directory if given, otherwise uses the pwd, and finds an Org
file and returns its parsed tree, or nil if none found."
  (when org-dir
      (cd (file-name-as-directory org-dir)))
  (let ((buf (car-safe (find-file-noselect "*.org" nil nil t))))
    (if buf
	(with-current-buffer buf (org-element-parse-buffer))
      nil)))
#+end_src

*** Check for CID
This code  checks whether an  Org file contains  a =custom_id= of  a particular
value.  It accepts  a ~cid-value~ and an optional directory.   If the directory
is not given, then it defaults to the current directory.  If throws an error if
the directory does not exist.  It returns =nil= if the given directory does not
contain an Org file.   It returns =t= if the Org file  contains a node property
of   =custom_id=  and   value  ~cid-value~,   or   =nil=  if   not.   It   uses
~get-parsed-org-tree~.

#+name:org-tree-cid-p
#+header: :results silent
#+begin_src emacs-lisp
(defun org-tree-cid-p (cid-value &optional org-dir)
  "Check whether an org file contains a custom_id of CID"
  (let ((tree (get-parsed-org-tree org-dir)))
    (car (org-element-map tree 'property-drawer
	   (lambda (pd) (org-element-map (org-element-contents pd) 'node-property
			  (lambda (np)
			    (and
			     (string= "custom_id" (org-element-property :key np))
			     (string= cid-value (org-element-property :value np))))))
	   nil t))))
#+end_src

#+name:run-org-tree-cid-p
#+header: :var cid="build-tools"
#+header: :var dir="/usr/local/dev/programming/MasteringEmacs"
#+header: :var gpot=get-parsed-org-tree()
#+header: :var otcp=org-tree-cid-p()
#+header: :results value
#+header: :eval never-export
#+begin_src emacs-lisp
(org-tree-cid-p cid dir)
#+end_src

#+call: run-org-tree-cid-p(dir="/usr/local/dev/programming/MasteringEmacs")

*** Keywords and Values
This function takes  an Org file name and optionally  a directory (otherwise it
uses the default  directory) and returns the  value of a keyword.   It does not
use a parse tree, but rather loops through the file line-by-line until it finds
the keyword and then returns its value.

#+name:get-keyword-value
#+begin_src emacs-lisp
  (defun get-keyword-value (keyword-to-get org-file-name &optional dir)
    "Returns the value of a keyword in an Org buffer identified by ORG-FILE-NAME.
  Uses the current directory unless an optional DIR is supplied.
  Returns NIL if none is found.  Rather than parsing the whole Org
  buffer into a tree, this function simply starts at the beginning
  of the file and loops line by line through the file, returning
  when the key has been found or it reaches the end of the file."
    (with-current-buffer
	(find-file-noselect
	 (concat
	  (if dir (file-name-as-directory dir) default-directory)
	  org-file-name))
      (save-excursion
	(goto-char (point-min))
	(let ((done nil)
	      (ans nil))
	  (while (not done)
	    (let* ((el (org-element-at-point))
		   (ty (org-element-type el))
		   (key (org-element-property :key el))
		   (val (org-element-property :value el)))
	      (when (and
		     (string-equal ty "keyword")
		     (string-equal key keyword-to-get))
		(setq ans val done t))
	      (forward-line)
	      (when (eobp)
		(setq done t))))
	  ans))))
#+end_src

#+name:get-title-for-org-buffer
#+begin_src emacs-lisp
(defun get-title-for-org-buffer (org-file-name &optional dir)
"A wrapper around `get-keyword-value' to find a TITLE in an Org buffer."
  (get-keyword-value "TITLE" org-file-name dir))
#+end_src

** Bucket Index HTML
The bucket should contain a master ~index.html~  file that links to each of the
individual project  ~index.html~ files.  The  master ~index.html~ file  will be
placed at the root of  the bucket, ~https://<bucket-name>.com/~, and the bucket
must be set up to serve this ~index.html~ when the user hits the root.

*** Get Bucket Name
 This  code searches  for  the keyword-value  pair =bucket:<BUCKET-NAME>=  that
 should be  located towards the  beginning of the  file, and returns  the value
 =BUCKET-NAME= or nil if not found.

#+name: get-bucket-name
#+header: :results value
#+begin_src emacs-lisp
   (save-excursion
     (goto-char (point-min))
     (re-search-forward "^#\\+bucket:\\s*?\\(.*\\)$" nil t)
     (match-string-no-properties 1))
#+end_src

For some reason, ~get-bucket-name~ does not  work when called from the headline
[[#project-index-links][=Links for  bucket=]] below  when creating  =index.html=, even  if it  returns as
~(prin1 ...)~ and is  set up to ~:return output~; the  call receives =nil=. The
following code from ~bucket-name~, however, works. I don't know why.

#+name: bucket-name
#+header: :results output
#+header: :var bucket-name=get-bucket-name()
#+begin_src emacs-lisp
(prin1 bucket-name)
#+end_src

*** Bucket HTTPS URL
This  code calls  ~get-bucket-name~ and  returns the  value returned  as a  URL
string or nil.

#+name: bucket-https-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "https://" b)
#+end_src

*** S3 Bucket URL
This code calls ~get-bucket-name~ and returns the AWS S3 bucket url.

#+name: s3-bucket-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "s3://" b)
#+end_src

*** Bucket Projects List
This code uses the ~s3-bucket-url~ result to obtain the list of projects in the
bucket.  It does  this by calling the  AWS S3 high-level command  ~ls~ and then
removing the  =PRE= string in  each result.  The result  that is returned  is a
single  string that  can be  separated into  individual links  by breaking  the
string on spaces.

#+name: bucket-projects-list
#+header: :results output
#+header: :var bucket=s3-bucket-url()
#+begin_src sh
/usr/local/bin/aws s3 ls ${bucket} | sed -ne 's/^.*PRE //p'
#+end_src

*** Bucket Project Links
This code  uses the result  from ~bucket-projects-list~ to create  an unordered
list of  links written to  bucket projects, written  in Org-mode syntax.  It is
executed by a =#+call:= in [[*Bucket Index][*Bucket  Index]] during an HTML export of that subtree
to a file called =index.html=.

#+name: bucket-project-links
#+header: :var b-url=bucket-https-url()
#+header: :var projects=bucket-projects-list()
#+header: :results output raw
#+begin_src emacs-lisp
(seq-do (lambda (u) (princ (format "- [[%s/%sindex.html][~%s~]]
" b-url u u))) (split-string projects))
#+end_src

*** Bucket Index
    :PROPERTIES:
    :custom_id: project-index-title
    :export_file_name: index.html
    :export_subtitle: {{{version}}} created {{{upload-date}}}
    :END:
#+html_doctype: html5
#+options: toc:nil html5-fancy:t

#+html: <hr>

**** Links for bucket call_bucket-name()
     :PROPERTIES:
     :unnumbered: t
     :custom_id: project-index-links
     :END:

#+call: bucket-project-links()
** Project Readme
This adds the README.md template to a project. It should be customized uniquely
for the project.

#+name:project-readme
#+header: :tangle README.md
#+begin_src markdown
# TITLE
## Subtitle
## Author
## Date
## Version
# ABSTRACT
This is the Org Template file.	It is the parent of all other Org Info blogs,
and provides the source code for processing them in various different ways.
# INTRODUCTION
# CHAPTER
## Section
### Subsection
#+end_src

** Boot Template
:PROPERTIES:
:dependency1: EMACS:=:/Applications/MacPorts/Emacs.app/Contents/MacOS/Emacs or similar
:dependency2: EDITOR:=:emacsclient
:dependency3: =SYNC_ORG_TEMPLATE= defined as $DEV/Templates/Org/Template.org
:END:
Although running the command ~org-babel-tangle~ (=C-c C-v t=) from within Emacs
will install  everything, it would  be nice to have  a simple Makefile  that is
downloaded with this  file that could be  invoked to do the  same thing without
starting Emacs and Org-mode and keying in the ~org-babel-tangle~ command.  This
little Makefile should be stored on  GitHub along with the ~Template.org~ file.
When  the source  is extracted  to a  directory, then  running this  Makefile's
default rule  as simply ~make~  will extract the ~preprocess.el~  script, which
updates  =DEV= and  then  extracts the  full Makefile.   Because  this file  is
tangled along with the full Makefile, it simply gets tacked onto the end of the
big Makefile  as an additional rule.   After 'preprocess.el' runs, and  the new
Makefile  is  extracted,  the  script  runs 'git'  to  update  the  repository,
including pushing the changes to Github.

Now, running ~make~ runs  the default rule from the main  Makefile, which is to
extract everything, then export to TEXI, INFO, HTML, and PDF forms.

It is assumed that an Emacs server is running, and that the $EDITOR environment
variable is set to use ~emacsclient~.

#+name:boot-template
#+header: :tangle Makefile
#+begin_src makefile
  boot:
	  $(EDITOR) -u --eval \
		  "(with-current-buffer (car (find-file-noselect \"./*.org\" nil nil t)) \
			  (goto-char (point-min)) \
			  (re-search-forward \"^#[+]name:preprocess.el$$\") \
			  (org-babel-tangle (quote (4))) \
			  (save-buffer) \
			  (kill-buffer))" \
	  --eval \
		  "(let ((rsrcdir \"resources\") \
			 (subdirs (list \"tools\" \"images\"))) \
		     (mkdir rsrcdir t) \
		     (dolist (subdir subdirs) (mkdir (concat rsrcdir \"/\" subdir) t)))"
	  ./resources/tools/preprocess.el
	  git add . && git commit -m "After running boot-template Makefile" && git push origin master
#+end_src

** Preprocess Env Vars
The environment variable DEV can be  in different locations and will be spelled
differently based  on how the  local machine is set  up.  For instance,  on one
system,  it will  be at  ~$HOME/Dev~  while in  another  system it  will be  at
~/usr/local/dev~.  However, the =:tangle= keyword  does not expand variables in
the form ~${DEV}~,  but rather requires absolute  paths, like ~/usr/local/dev~.
Therefore, this program works like a preprocessor for environment variables set
up  as part  of  =:tangle= lines,  changing them  to  their system  environment
variable values prior to tangling.  It lives in the ~resources/tools~
directory.

- *NOTE:  [2021-09-15 Wed  23:30]* The  assumption  that the  emacs program  is
  located   at  ~/opt/local/bin/~   is   incorrect.   Perhaps   it  should   be
  ~#!/usb/bin/env emacs~ instead.

#+name:preprocess.el
#+header: :mkdirp t
#+header: :tangle resources/tools/preprocess.el
#+header: :shebang "#!/usr/bin/env emacs -Q --script"
#+begin_src emacs-lisp
  (with-current-buffer (car (find-file-noselect "./*.org" nil nil t))
    (save-excursion
    (goto-char (point-min))
    (let ((re-search-str "\\(?::tangle\\|load-file \\(?:[\\]*\\)?[\"]\\)\s*\\(.*?/[dD]ev\\)/")
          (dev (getenv "DEV")))
      (while
              (re-search-forward re-search-str nil t)
              (replace-match dev t nil nil 1)))
    (save-buffer)
    (require 'org)
    (org-babel-tangle)))
#+end_src

** Samples
#+begin_comment
(cd "~/Dev/Emacs/MasteringEmacs/")
"/Users/pine/Dev/Emacs/MasteringEmacs/"

(defun add-bucket (org bucket)
  "Add a bucket keyword BUCKET to the org file ORG."
  (interactive "fFile: \nsBUCKET: ")
  (with-current-buffer (find-file-noselect org)
    (let* ((tree (org-element-parse-buffer))
	   (ins (car (org-element-map tree (quote section)
		 (lambda (s)
		   (org-element-map s (quote keyword)
		     (lambda (kw) (when (equal "MACRO" (org-element-property :key kw)) (1- (org-element-property :end kw))))
		     nil nil :keyword))
		 nil t nil nil))))
      (goto-char ins)
      (insert (format "#+bucket:%s\n" bucket))
      ())))

(add-bucket "MasteringEmacs.org" "pinecone-forest")
nil

(defun hl-region (raw-hl)
  "Obtain the begin and end positions for a headline."
  (with-current-buffer (find-file-noselect (getenv "SYNC_ORG_TEMPLATE"))
    (let* ((tree (get-parsed-tree))
	   (hl (car-safe (org-element-map tree 'headline
			   (lambda (hl) (when
					    (string= raw-hl
						     (org-element-property :raw-value hl))
					  (org-element-context)))
			   nil nil t))))
      (cons
       (org-element-property :begin hl)
       (org-element-property :end hl))
      )))

(hl-region "Build Tools")

(4888 . 29646)

(defun get-hl-with-prop (org-dir hl-prop)
  "Given a directory containing an Org template file and a custom_id property name, return the headline containing that custom_id, or nil if none."
  (progn
    (cd org-dir)
    (let ((org-buf (car-safe (find-file-noselect "*.org" nil nil t))))
      (if org-buf
	  (with-current-buffer org-buf
	    (let ((tree (org-element-parse-buffer)))
	      (org-element-map tree 'headline
		(lambda (hl)
		  (let ((cid (org-element-property :CUSTOM_ID hl)))
		    (when (string= hl-prop cid)
		      (and
		       (message (format "Found the headline %s containing property %s." (org-element-property :raw-value hl) hl-prop))
		       hl))))
		nil t)))
	(and
	 (message (format "The directory %s does not contain an Org file." org-dir))
	 nil)))))

(get-hl-with-prop "~/Dev/Templates/Org" "build-tools")

(headline (:raw-value "Build Tools" :begin 4888 :end 29646 :pre-blank 0 :contents-begin 4902 :contents-end 29645 :level 1 :priority nil :tags nil :todo-keyword nil :todo-type nil :post-blank 1 :footnote-section-p nil :archivedp nil :commentedp nil :post-affiliated 4888 :FROM-FILE "Template" :CUSTOM_ID "build-tools" :APPENDIX "t" :title "Build Tools"))









;;; Add a keyword named 'bucket' just after the version macro.
;;; This function should be run from within the directory containing the Org file.
(defun add-bucket (org-file s3-bucket)
  "Add the name of the associated AWS S3 bucket to an Org templated file."
  (with-current-buffer (find-file-noselect org-file)
    (goto-char (point-min))
    (let* ((tree (org-element-parse-buffer))
	   ;; find the beginning position of the first headline to act as a limit
	   (hl1 (org-element-map tree (quote headline) (lambda (hl) (org-element-property :begin hl)) nil t)))
      ;; Check for the presence of a bucket keyword before the first headline
      (unless (re-search-forward "^#\\+bucket:" hl1 t)
	;; If no bucket keyword is found, search for a keyword MACRO with the value 'version'
	(org-element-map tree (quote keyword)
	  (lambda (kw) (when (and (string= "MACRO" (org-element-property :key kw))
				  (string-match-p "version" (org-element-property :value kw)))
			 ;; return the end position of the MACRO; subtract an empty line if there is one
			 (goto-char (- (org-element-property :end kw) (org-element-property :post-blank kw)))
			 (insert "#+bucket:" s3-bucket)
			 (newline)
			 (basic-save-buffer)
			 (message (format "Added bucket %s" s3-bucket))))
	  nil t)))))

(add-bucket "MasteringEmacs.org" "pinecone-forest.com")
nil

"Added bucket pinecone-forest.com"









(keyword (:key "MACRO" :value "version Version 0.0.108" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...))
("TITLE" "SUBTITLE" "AUTHOR" "DATE" "MACRO" "TEXINFO" "TEXINFO" "CINDEX" "CINDEX" "CINDEX" "CINDEX" "CINDEX" ...)







((keyword (:key "MACRO" :value "version Version 0.0.107" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...)))
#+end_comment

* List of Programs
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Listing

* List of Examples
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Example

* List of Tables
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Table

* Copying
:PROPERTIES:
:copying:  t
:END:

Copyright \copy 2020 by {{{author}}}

* Concept Index
:PROPERTIES:
:index: cp
:appendix: yes
:END:

* Program Index
:PROPERTIES:
:index: pg
:appendix: yes
:END:

* Function Index
:PROPERTIES:
:index: fn
:appendix: yes
:END:

* Variable Index
:PROPERTIES:
:index: vr
:appendix: yes
:END:


* Configuration							   :noexport:
#+startup:content

#+todo: SOMEDAY(s@) TODO(t@) INPROGRESS(i@) WAIT(w@) | CANCEL(c@) DONE(d!)

#+options: H:4 ':t

#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+texinfo_dir_category:<DIR CATEGORY>
#+texinfo_dir_title:<DIR TITLE>
#+texinfo_dir_desc:<DIR DESCRIPTION>
#+texinfo_printed_title:GoPL---Go Programming Language


* Footnotes

[fn:1]In the browser, add =index.text= to the end of the URL to see the source.

[fn:2]Markdown requires the standard Perl library module Digest::MD5.


* Local Variables						   :noexport:
# Local Variables:
# fill-column: 79
# indent-tabs-mode: t
# eval: (auto-fill-mode)
# time-stamp-pattern: "8/^\\#\\+date:%:y-%02m-%02d %02H:%02M$"
# End:
